{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BE cGAN","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"UGwKsKS4GMTN","colab_type":"text"},"cell_type":"markdown","source":["<h1 ><big><center>Deep Learning 2019/2020</center></big></h1>\n","\n","<h3><big><center>Liming Chen</center></big></h3>\n","\n","\n","<h2><big><center> Assignment (3?): GANs </center></big></h2>\n","\n","<h5><big><center>Adapted from 'Projet d'Option' of : Mhamed Jabri, Martin Chauvin, Ahmed Sahraoui, Zakariae Moustaïne and Taoufik Bouchikhi\n","\n","\n","<p align=\"center\">\n","<img height=300px src=\"https://cdn-images-1.medium.com/max/1080/0*tJRy5Chmk4XymxwN.png\"/></p>\n","<p align=\"center\"></p>"]},{"metadata":{"id":"wPOeHZlaIHQa","colab_type":"text"},"cell_type":"markdown","source":["In this notebook we will explore the use of *Genarative Adversarial Networks (GAN)* for generating new images.\n","\n","There are several types of neural nets, GANs use 2 types of them. The discriminator is a neural net that given data tries to extract knowledge. The generator is a neural network that given data tries to generate data.\n","\n","![**Insert picture showing architectures here**](img/architectures.png)\n","\n","\n","\n","\n","*When training a model, we define a loss function which measures our current unhappiness with the model's performance; we then use backpropagation to compute the gradient of the loss with respect to the model parameters, and perform gradient descent on the model parameters to minimize the loss.*\n","\n","*Here we will do something slightly different. We will start from a convolutional neural network model which has been pretrained to perform image classification on the ImageNet dataset. We will use this model to define a loss function which quantifies our current unhappiness with our image, then use backpropagation to compute the gradient of this loss with respect to the pixels of the image. We will then keep the model fixed, and perform gradient descent on the image to synthesize a new image which minimizes the loss.*\n","\n","*In this notebook we will explore three techniques for image generation:*\n","\n","*Saliency Maps: Saliency maps are a quick way to tell which part of the image influenced the classification decision made by the network.\n","Fooling Images: We can perturb an input image so that it appears the same to humans, but will be misclassified by the pretrained network.\n","Class Visualization: We can synthesize an image to maximize the classification score of a particular class; this can give us some sense of what the network is looking for when it classifies images of that class.\n","This notebook uses PyTorch.*"]},{"metadata":{"id":"SuHD5_7mI--5","colab_type":"text"},"cell_type":"markdown","source":["Partie 1 : CNN (déjà vu vite fait en cours) -> finalité, construire un UNET avec pytorch\n","\n","Partie 2 : GANs -> finalité : comprendre le fonctionnement, construire un GAN basique (rien à voir avec notre projet di'nfo, juste pour avoir une idée)\n","\n","Partie 3 : cGAN -> finalité : construire un bloc discriminant\n","\n","Partie 4 : train + load des poids + application sur la BD des façades"]},{"metadata":{"id":"jbRl2-2c1GQq","colab_type":"code","colab":{}},"cell_type":"code","source":["%matplotlib inline\n","\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gLoFU9UnDK8q","colab_type":"text"},"cell_type":"markdown","source":["## GAN"]},{"metadata":{"id":"rr-IlmeaFBNn","colab_type":"text"},"cell_type":"markdown","source":["The aim of this section is to present the process of creating a simple Generative Adverserial Network to generate hand-written numbers.\n","This GAN will be made of 2 Neural Networks :\n","* A discriminator which will try to determine wether an picture is a real one (from the dataset) or was generated\n","* A generator which will generate images in order to fool the discriminator\n","\n","These 2 Neural Nets will both be fully connected."]},{"metadata":{"id":"-Jsy4IoNg06E","colab_type":"text"},"cell_type":"markdown","source":["### Discriminator\n","\n","The discriminator network is going to be a pretty typical linear classifier. It will be made of 3 hidden layers, will be activated with a leaky ReLu and use dropout layers."]},{"metadata":{"id":"DteCngtHE5IW","colab_type":"code","colab":{}},"cell_type":"code","source":["class Discriminator(nn.Module):\n","\n","    def __init__(self, input_size, hidden_dim, output_size):\n","        super(Discriminator, self).__init__()\n","        \n","        # define hidden linear layers\n","        self.fc1 = nn.Linear(input_size, hidden_dim*4)\n","        self.fc2 = nn.Linear(hidden_dim*4, hidden_dim*2)\n","        self.fc3 = nn.Linear(hidden_dim*2, hidden_dim)\n","        \n","        # final fully-connected layer\n","        self.fc4 = nn.Linear(hidden_dim, output_size)\n","        \n","        # dropout layer \n","        self.dropout = nn.Dropout(0.3)\n","        \n","        \n","    def forward(self, x):\n","        # flatten image\n","        x = x.view(-1, 28*28)\n","        # all hidden layers\n","        x = F.leaky_relu(self.fc1(x), 0.2) # (input, negative_slope=0.2)\n","        x = self.dropout(x)\n","        x = F.leaky_relu(self.fc2(x), 0.2)\n","        x = self.dropout(x)\n","        x = F.leaky_relu(self.fc3(x), 0.2)\n","        x = self.dropout(x)\n","        # final layer\n","        out = self.fc4(x)\n","\n","        return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Vg5jasGzhneR","colab_type":"text"},"cell_type":"markdown","source":["### Generator\n","\n","The generator network will be almost exactly the same as the discriminator network, except that we're applying a tanh activation function to our output layer."]},{"metadata":{"id":"Qd6gFzBTDNNG","colab_type":"code","colab":{}},"cell_type":"code","source":["class Generator(nn.Module):\n","\n","    def __init__(self, input_size, hidden_dim, output_size):\n","        super(Generator, self).__init__()\n","        \n","        # define hidden linear layers\n","        self.fc1 = nn.Linear(input_size, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, hidden_dim*2)\n","        self.fc3 = nn.Linear(hidden_dim*2, hidden_dim*4)\n","        \n","        # final fully-connected layer\n","        self.fc4 = nn.Linear(hidden_dim*4, output_size)\n","        \n","        # dropout layer \n","        self.dropout = nn.Dropout(0.3)\n","\n","    def forward(self, x):\n","        # all hidden layers\n","        x = F.leaky_relu(self.fc1(x), 0.2) # (input, negative_slope=0.2)\n","        x = self.dropout(x)\n","        x = F.leaky_relu(self.fc2(x), 0.2)\n","        x = self.dropout(x)\n","        x = F.leaky_relu(self.fc3(x), 0.2)\n","        x = self.dropout(x)\n","        # final layer with tanh applied\n","        out = F.tanh(self.fc4(x))\n","\n","        return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z1fNAEiEiCg7","colab_type":"text"},"cell_type":"markdown","source":["### Build the network"]},{"metadata":{"id":"z3cv4klXiBss","colab_type":"code","colab":{}},"cell_type":"code","source":["# Discriminator hyperparams\n","\n","# Size of input image to discriminator (28*28)\n","input_size = 784\n","# Size of discriminator output (real or fake)\n","d_output_size = 1\n","# Size of last hidden layer in the discriminator\n","d_hidden_size = 32\n","\n","# Generator hyperparams\n","\n","# Size of latent vector to give to generator\n","z_size = 100\n","# Size of discriminator output (generated image)\n","g_output_size = 784\n","# Size of first hidden layer in the generator\n","g_hidden_size = 32"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MM8QUM5ZiKsE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"outputId":"4adfa922-b7ea-4588-bc8e-4120120a6b47","executionInfo":{"status":"ok","timestamp":1551633009749,"user_tz":-60,"elapsed":614,"user":{"displayName":"Martin Chauvin","photoUrl":"https://lh4.googleusercontent.com/-Q1DEKr2s-Nk/AAAAAAAAAAI/AAAAAAAAABQ/bBu9kso7NGs/s64/photo.jpg","userId":"16826705269328235112"}}},"cell_type":"code","source":["# instantiate discriminator and generator\n","D = Discriminator(input_size, d_hidden_size, d_output_size)\n","G = Generator(z_size, g_hidden_size, g_output_size)\n","\n","# check that they are as you expect\n","print(D)\n","print()\n","print(G)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Discriminator(\n","  (fc1): Linear(in_features=784, out_features=128, bias=True)\n","  (fc2): Linear(in_features=128, out_features=64, bias=True)\n","  (fc3): Linear(in_features=64, out_features=32, bias=True)\n","  (fc4): Linear(in_features=32, out_features=1, bias=True)\n","  (dropout): Dropout(p=0.3)\n",")\n","\n","Generator(\n","  (fc1): Linear(in_features=100, out_features=32, bias=True)\n","  (fc2): Linear(in_features=32, out_features=64, bias=True)\n","  (fc3): Linear(in_features=64, out_features=128, bias=True)\n","  (fc4): Linear(in_features=128, out_features=784, bias=True)\n","  (dropout): Dropout(p=0.3)\n",")\n"],"name":"stdout"}]},{"metadata":{"id":"5fbSgsrE1GqC","colab_type":"text"},"cell_type":"markdown","source":["## CNN"]}]}